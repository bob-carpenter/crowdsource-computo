---
title: "A Binary Rating Model for Heterogeneous Items"
subtitle: "Adjusting for item difficulty, discriminativeness, and guessability"
author:
  - name: Bob Carpenter
    corresponding: true
    email: bcarpenter@flatironinstitute.org
    url: https://bob-carpenter.github.io/
    orcid: 0000-0002-2433-9688
    affiliations:
      - name: Flatiron Institute
        department: Center for Computational Mathematics
        url: https://www.simonsfoundation.org/flatiron/center-for-computational-mathematics/
date: last-modified
date-modified: last-modified
description: |
abstract: >+
  Dawid and Skene's crowdsourcing model fails to capture important distributional properties of real rating data.  By adding effects for difficulty, discriminativeness, and guessability, the annotation model is able to more closely model the true data generating process.  This is illustrated with data from dental image classification and natural language inference.
keywords: [rating, coding, Bayesian, IRT, Stan, Python, Dawid-Skene]
citation:
  type: article-journal
  container-title: "Computo"
  doi: "xxxx"
  url: https://computo.sfds.asso.fr/template-computo-quarto
  publisher: "Société Française de Statistique"
  issn: "2824-7795"
bibliography: references.bib
github-user: bob-carpenter
repo: "crowdsource-computo"
draft: true # set to false once the build is running
published: false # will be set to true once accepted
format:
  computo-html: default
  computo-pdf: default
jupyter: python3
---

# Introduction

This note considers the rating problem for classification.  An example analyzed later is a data set of roughly dental 4000 X-rays, each of which is rated by 5 dentists as to whether the patient had caries (a kind of pre-cavity).  The dentists showed surprisingly little agreement, with only 100 X-rays having consensus of caries being present.  The dentists also varied dramatically in the number of cases each rated as having caries.  There are several goals for a rating mode, wuch as combining ratings into a consensus analysis, analyzing the accuracy and bias of the individual raters, analyzing the difficulty of the rating task, and analyzing the prevalence of caries among the population represented by the X-rays.  The results may also be used to guide active learning in data acquisition by assessing the information gain from gathering a rating from either a known or a new rater.

One of the main applications is in crowdsourcing, where typically untrained or lightly trained workers perform bulk ratings of highly variable quality.  But these models are equally useful when applied to expert ratings, where expertise is measured in terms of rating accuracy and bias.

Rating models show up in multiple fields from educational testing, from where we will draw much of the inspiration for the contribution here, in epidemiology where they are applied to diagnostic tests, in sociology where they are applied to exploring cultural norms, and in data curation for machine learning where they are applied to human feedback on classification or other problems.  As one example, human tags on images are used to train large-scale image classifiers like ImageNet, which has over a million images classified into a thousand classes.  As another example, crowdsourced ratings of language model output are used as a fine-tuning step that adjusts a foundational large language model like GPT-4, which is trained to complete text, into a chatbot like ChatGPT that is (imperfectly) trained to be helpful, truthful, and harmless.


# A General Crowdsourcing Model

This section presents the most general crowdsourcing model, then considers how it may be simplified by removing features.  Removing features here amounts to tying parameters, such as assuming all raters have the same accuracy or all items have the same difficulty.

## The rating data

Consider a crowdsourcing problem for which there are $I \in \mathbb{N}$ items to rate and $J \in \mathbb{N}$ raters to do the rating.  Long-form data will be used to accomodate there being a varying number of raters per item and a varying number of items per rater.  let $N \in \mathbb{N}$ be the number of ratings $\textrm{rating}_n \in \{0, 1 \}$, each of which is equipped with a rater $\textrm{rater}_n \in 1:J$ and item being rated $\textrm{item}_n \in 1:I$.

For each item $i$, suppose there are covariates $x_i \in \mathbb{R}^K$.  Then $x \in \mathbb{R}^{I \times K}$ is the full data matrix and $x_i$ is naturally considered a row vector.  In the simplest case, $K = 1$ and $x$ is a single column of 1 values representing an intercept.  In the more general case, other features may denote information relevant for classifying the item, such as the pixels of an image for image classification, demographic information for predicting a vote in an election, or medical test results for predicting a medical condition.

## The complete data likelihood

The foundation of the model is a diagnostic testing sensitivity and specificity model, which is widely used in epidemiology.  This simple foundation is extended to adjust for difficulty, discrimination, and guessing using the parameterization of the item-response theory three-parameter logistic (IRT 3PL) model, a widely used educational testing model.

### Latent category marginal likelihood

For each item, let $z_i \in \{ 0, 1 \}$ be its (unobserved/latent) category, with a 1 conventionally denoting "success" or a "positive" result.  The complete data likelihood is complete in the sense that it includes the latent category.  Marginalizing out this category, the technical details and numerical stability of which are deferred until later, leads to the ordinary likelihood function used in the model to avoid challenging inference over discrete parameters.

Let $\beta \in \mathbb{R}^K$ be a vector of (unobserved) regression coefficients.  The marginal likelihood for the category is in the form of a logistic regression,
\begin{equation}
z_i \sim \textrm{bernoulli}\!\left(\textrm{logit}^{-1}(x_i \cdot \beta)\right).
\end{equation}
An intercept may be included as a column of 1 values in the data matrix.  Other regression models could be substituted for the logistic regression, such as a neural network model.  All that is needed is a way to go from predictors ($x_i$) and parameters ($\beta) to the log odds of a positive (1) outcome ($x_i \cdot \beta$).

### Rating conditional likelihood

The rating from rater $j$ for item $i$ is generated conditionally given the category $z_i$ of an item.  For positive items $z_i = 1$), sensitivity (accuracy on positive items) is used, whereas for negative items ($z_i = 0$), specificity (accuracy on negative items) is used.  Thus every rater $j$ will have a sensitivity $\alpha^{\textrm{sens}}_j \in \mathbb{R}$ and a specificity $\alpha^{\textrm{spec}}_j$ on the log odds scale (it will be adjusted for item difficulty and discriminativeness and then logistically transformed to a probability).  If the sensitivity is higher than the specificity there will be a bias toward 1 ratings, whereas if the specificity is higher than the sensitivity, there is a bias toward 0 ratings.  If the model only has sensitivity and specificity parameters for raters, it reduces to Dawid and Skene's diagnostic testing model.  Fixing $\alpha^{\textrm{sens}} = \alpha^{\textrm{spec}}$ introduces an unbiasedness assumption whereby a rater has equal sensitivities and specificities.

The items are parameterized with a difficulty $\beta_i \in \mathbb{R}$ on the log odds scale.  This difficulty is subtracted form the sensitivity (if $z_i = 1$) or specificity (if $z_i = 0$) as appropriate to give the raw log odds of a correct rating (i.e., a rating matching the true category $z_i$).  Fixing $\beta_i = 0$ introduces the assumption that every item is equally difficult.

Each item is further parameterized with a positive-constrained discrimination parameter $\delta_i \in (0, \infty)$.  This is multiplied by the raw log odds to give a discrimation-adjusted log odds to give a probability of correctly rating the item.  The higher the discrimination, the more likely a rater with ability above the difficulty will get the correct answer and th emore likely a rater with ability below the difficulty will get the incorrect answer.  For educational testing, high discrimation test questions are preferable, but for rating wild type data, low discrimination is also possible when there are low signal data items.  Fixing $\delta_i = 1$ introduces the assumption that the items are equally discriminative.

The final parameter associated with an item is a guessability parameter $\lambda_i \in (0, 1)$, giving the probability that a rater can just "guess" the right answer.  Fixing $\lambda_i = 0$ introduces the assumption that the raters never guess an answer.

The full model follows the IRT-3PL model, where the probability that rater $j$ assigns the correct rating to item $i$ is given by
\begin{equation}
y \sim \textrm{binomial}\!\left(\lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\delta_i \cdot (\alpha^k_j - \beta_i))\right),
\end{equation}
where $k = \textrm{sens}$ if $z_i = 1$ and $k = \textrm{spec}$ if $z_i = 0.$  To convert to the distribution over rating data, the probability must be flipped when $z_i = 0$ so that a 90\% accurate rating results in a 90% chance of a 0 rating,
\begin{equation}
y \sim
\begin{cases}
\textrm{binomial}\!\left(\lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}\!\left(\delta_i \cdot \left(\alpha^\textrm{sens}_j - \beta_i\right)\right)\right)
& \textrm{if } z_i = 1, \textrm{ and}
\\[4pt]
\textrm{binomial}\!\left(1 - \left( \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}\!\left(\delta_i \cdot \left(\alpha^\textrm{sens}_j - \beta_i\right)\right)\right)\right)
& \textrm{if } z_i = 0.
\end{cases}
\end{equation}
The second case ($z_i = 0$) reduces to
\begin{equation}
\textrm{binomial}\!\left( \left( 1 - \lambda_i \right)
                \cdot \left( 1 - \textrm{logit}^{-1}\!\left(\delta_i \cdot \left(\alpha^\textrm{sens}_j - \beta_i\right)\right)\right)\right),
\end{equation}
and reduces further to
\begin{equation}
\textrm{binomial}\!\left( \left( 1 - \lambda_i \right)
                \cdot \textrm{logit}^{-1}\!\left(-\delta_i \cdot \left(\alpha^\textrm{sens}_j - \beta_i\right)\right)\right).
\end{equation}
The table below summarizes the reduced models, where the reductions are

| Reduction | Description | Tag |
|:---------:|:-----------:|:---:|
| $\lambda_i = 0$ |  no guessing | A |
| $\delta_i = 1$ | equal discrimination | B |
| $\beta_i = 0$ |equal difficulty | C |
| $\alpha^{\textrm{spec}} = \alpha^{\textrm{sens}}$ | unbiased | D |
| $\alpha_j = \alpha_j'$ | identical raters | E |


The first list contains models that model bias by splitting accuracy into sensitivity and specificity components.  Models without a sensitivity versus specificity distinction make sense when the categories are not ordered.  For example, asking consumers which brand is their favorite between two brands at a time, the labels 0 and 1 are arbitrary, and sensitivity should be equal to specificity.  The following models do not distinguish sensitivty and specificity.

\begin{equation}
\begin{array}{cc}
\textrm{Reductions} & \textrm{Probability Correct} \\ \hline
D
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\delta_i \cdot (\alpha_j - \beta_i))
\\ 
CD
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\delta_i \cdot \alpha_j)
\\
BD
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\alpha_j - \beta_i)
\\ \hline
BCD
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\alpha_j)
\\
AD
& \textrm{logit}^{-1}(\delta_i \cdot (\alpha_j - \beta_i))
\\
ACD
& \textrm{logit}^{-1}(\delta_i \cdot \alpha_j)
\\ \hline
ABD
& \textrm{logit}^{-1}(\alpha_j - \beta_i)
\\
ABCD
& \textrm{logit}^{-1}(\alpha_j)
\\
ABCDE
& \textrm{logit}^{-1}(\alpha)
\end{array}
\end{equation}
The final model in the list is the only model that does not distinguish among the raters, using a single accuracy parameter.

The following models introduce separate parameters for sensitivity and specifity rather than assuming they are the same.
\begin{equation}
\begin{array}{cc}
\textrm{Reductions} & \textrm{Probability Correct} \\ \hline
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\delta_i \cdot (\alpha^k_j - \beta_i))
\\
C
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\delta_i \cdot \alpha^k_j)
\\
BC
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\alpha^k_j)
\\ \hline
A
& \textrm{logit}^{-1}(\delta_i \cdot (\alpha^k_j - \beta_i))
\\
AC
& \textrm{logit}^{-1}(\delta_i \cdot \alpha^k_j)
\\
AB
& \textrm{logit}^{-1}(\alpha^k_j - \beta_i)
\\ \hline
ABC
& \textrm{logit}^{-1}(\alpha^k_j)
\\
ABCE
& \textrm{logit}^{-1}(\alpha^k)
\end{array}
\end{equation}
The final model in this list has a single sensitivity and specificity for all raters, whereas the other models have varying effects.

There is a single model that does not use any notion of rating accuracy at all, relying solely on item effects.
\begin{equation}
\begin{array}{cc}
\textrm{Reductions} & \textrm{Probability Correct} \\ \hline
ABDE
& \textrm{logit}^{-1}(- \beta_i) \quad
\\ \hline
\end{array}
\end{equation}

The remaining models are all redundant in the sense that fixing their non-identifiability issues reduces to a model with a single item effect.
\begin{equation}
\begin{array}{ccc}
\textrm{Reductions} & \textrm{Probability Correct} \\ \hline
E
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\delta_i \cdot (\alpha^k - \beta_i))
\\
DE
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\delta_i \cdot (\alpha - \beta_i))
\\
CE
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\delta_i \cdot \alpha^k)
\\ \hline
CDE
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\delta_i \cdot \alpha)
\\
BE
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\alpha^k - \beta_i)
\\
BDE
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\alpha - \beta_i)
\\ \hline
BCE
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\alpha^k)
\\
BCDE
& \lambda_i + (1 - \lambda_i) \cdot \textrm{logit}^{-1}(\alpha)
\\
AE 
& \textrm{logit}^{-1}(\delta_i \cdot (\alpha^k - \beta_i))
\\ \hline
ADE
& \textrm{logit}^{-1}(\delta_i \cdot (\alpha - \beta_i))
\\
ACE
& \textrm{logit}^{-1}(\delta_i \cdot \alpha^k)
\\
ACDE
& \textrm{logit}^{-1}(\delta_i \cdot \alpha)
\\ \hline
ABE
& \textrm{logit}^{-1}(\alpha^k - \beta_i)
\end{array}
\end{equation}

## About this document

This document, accompanied by the [customized GitHub repository](https://github.com/computorg/template-computo-python/), provides a template for writing contributions to **Computo** [@computo]. We show how `Python` code can be included and how the repository can be set up for triggering GitHub actions for rendering the document, with dependencies handled by `venv` and `pip`.

## Setup a GitHub repository for preparing your submission

You can start by clicking on the **"use this template"** button, on the top of the page of the [github repository associated with this document](https://github.com/computorg/template-computo-python/). Of course, you can set your repository private during the preparation of your manuscript.

## Quarto

[Quarto](https://quarto.org/) is a versatile formatting system for authoring documents integrating markdown, LaTeX and code blocks interpreted either via Jupyter or Knitr (thus supporting Python, R and Julia). It relies on the [Pandoc](https://pandoc.org/MANUAL.html) document converter.

## Requirements

You need [quarto](https://quarto.org/docs/get-started/) installed on your system and the [Computo extension](https://github.com/computorg/computo-quarto-extension) to prepare your document. For the latter, once quarto is installed, run the following to install the extension in the current directory (it creates an `_extension` directory which is ignored by git thanks to `.gitignore` by default):

```.bash
quarto add computorg/computo-quarto-extension
```

[`Python`](https://www.python.org/) and [`Jupyter`](https://jupyter.org/install) must be installed on your computer.

## Link with your usual tools

Quarto is expecting a `.qmd` markdown file, but will also works with a standard [Jupyter notebook](https://quarto.org/docs/get-started/hello/jupyter.html) file if you are used to it (it will just require to add the proper YAML metadata^[the same metadata as in the [`template-computo-python.qmd` file](https://github.com/computorg/template-computo-python/blob/main/template-computo-python.qmd) in the first cell, type "Raw", of the notebook]).

**Note**: _More advanced Jupyter-related functionality like Myst/Jupyter book are not supported in this Quarto setup. The markdown syntax inside the Jupyter notebook should follow the Quarto syntax (c.f. [below](#formatting)). If you are more comfortable with using Myst/Jupyter book, we provide a [specific template](https://github.com/computorg/template-computo-myst) but it will requires more formatting work for Computo editorial team, thus highly encourage authors to use the Quarto templates._

# Formatting

This section covers basic formatting guidelines for quarto documents.

To render a document, run `quarto render`. By default, both PDF and HTML documents are generated:

```.bash
quarto render template-computo-python.qmd # renders both HTML and PDF
```

::: {.callout-tip}
## Note

To check the syntax of the formatting below, you can use the `</> source` button at the top right of this document.
:::

## Basic markdown formatting

**Bold text** or _italic_

- This is a list
- With more elements
- It isn't numbered.

But we can also do a numbered list

1. This is my first item
2. This is my second item
3. This is my third item

## Mathematics

### Mathematical formulae

[LaTeX](https://www.latex-project.org/) code is natively supported[^lualatex], which makes it possible to use mathematical formulae:

[^lualatex]: We use [lualatex](https://lualatex.org/) for this purpose.

$$
f(x_1, \dots, x_n; \mu, \sigma^2) =
\frac{1}{\sigma \sqrt{2\pi}} \exp{\left(- \frac{1}{2\sigma^2}\sum_{i=1}^n(x_i - \mu)^2\right)}
$$

It is also posible to cross-reference an equation, see @eq-mylabel:

$$
\begin{aligned}
D_{x_N} & = \frac12
\left[\begin{array}{cc}
x_L^\top & x_N^\top \end{array}\right] \,
\left[\begin{array}{cc}  L_L & B \\ B^\top & L_N \end{array}\right] \,
\left[\begin{array}{c}
x_L \\ x_N \end{array}\right] \\
& = \frac12 (x_L^\top L_L x_L + 2 x_N^\top B^\top x_L + x_N^\top L_N x_N),
\end{aligned}
$$ {#eq-mylabel}

### Theorems and other amsthem-like environments

Quarto includes a nice support for theorems, with predefined prefix labels for theorems, lemmas, proposition, etc. see [this page](https://quarto.org/docs/authoring/cross-references.html#theorems-and-proofs). Here is a simple example:

::: {#thm-slln}
## Strong law of large numbers

The sample average converges almost surely to the expected value:

$$\overline{X}_n\ \xrightarrow{\text{a.s.}}\ \mu \qquad\textrm{when}\ n \to \infty.$$
:::

See @thm-slln.

## Python Code

Quarto uses either Jupyter or knitr to render code chunks. This can be triggered in the yaml header. In this tutorial, we use `Jupyter`  (`Python` and `Jupyter` must be installed on your computer).

``` yaml
---
title: "My Document"
author "Jane Doe"
jupyter: python3
---
```

`python` code chunks may be embedded as follows:

```{python python-code}
import numpy as np
x = np.random.normal(0, 1, 10)
x
```

## Figures

Plots can be generated as follows:

```{python stem-plot}
#| label: fig-stem-plot
#| fig-cap: "A basic Stem plot"

import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(0.1, 2 * np.pi, 41)
y = np.exp(np.sin(x))

plt.stem(x, y)
plt.show()
```

It is also possible to create figures from static images:

:::{#fig-logo}

![](https://computo.sfds.asso.fr/assets/img/logo_text_vertical.png){height=200}

Computo logo (label)
:::


## Tables

Tables (with label: `@tbl-mylabel` renders @tbl-mylabel) can be generated with markdown as follows

| Tables   |      Are      |  Cool |
|----------|:-------------:|------:|
| col 1 is |  left-aligned | $1600 |
| col 2 is |    centered   |   $12 |
| col 3 is | right-aligned |    $1 |
: my table caption {#tbl-mylabel}

## Handling references {#sec-references}

### Bibliographic references

References are displayed as footnotes using
[BibTeX](http://www.bibtex.org/), e.g. `[@computo]` will be displayed
as [@computo], where `computo` is the bibtex key for this specific
entry. The bibliographic information is automatically retrieved from
the `.bib` file specified in the header of this document (here:
`references.bib`).

### Other cross-references

As already (partially) seen, Quarto includes a mechanism similar to the
bibliographic references for sections, equations, theorems, figures,
lists, etc. Have a look at [this
page](https://quarto.org/docs/authoring/cross-references.html).

## Advanced formatting

Advanced formatting features are possible and documented (including interactive plots, pseudo-code, (Tikz) diagrams, Lua filters, mixing R + Python in the same document), but are beyond the scope of this simple introduction. We point several entries in this direction.

::: {.callout-warning}
## More information

- [The Quarto web site](https://quarto.org) for comprehensive documentation, including:
  + [Tutorial](https://quarto.org/docs/get-started/)
  + [User guide](https://quarto.org/docs/guide/)
  + [Options reference](https://quarto.org/docs/reference/)

- [The template distributed with the Computo Quarto extension](https://computo.sfds.asso.fr/computo-quarto-extension/), which uses such advanced features.

- [Our mock version of the t-SNE paper](https://computo.sfds.asso.fr/published-paper-tsne/), a full and advanced example using Python and the Jupyter kernel.

- [The previously published papers in Computo](https://computo.sfds.asso.fr/publications/) can be used as references.

:::

# Finalize your submission

## Handle `Python` dependencies with `venv`

To make your work reproducible, you need to fix the packages and environment used to run your analysis. For `Python`, `venv` is one of the possible reliable method, supported by the community. You basically need a couple of commands to setup your environment on your local machine. First, to create a new virtual environment in the directory `my_env`

``` .bash
python3 -m venv my_env
```

and activate it

``` .bash
source my_env/bin/activate
```

Then installed the packages required to perform your analysis. Here,

``` .bash
python3 -m pip install jupyter matplotlib numpy
```

Once you are all set up, you need to save your working environment into a file so that anyone can reproduce your analysis on their side:

``` .bash
python3 -m pip freeze > requirements.txt
```

The corresponding `requirements.txt` file [found in this repository](https://github.com/computorg/template-computo-python/blob/main/requirements.txt) is then

```{.bash filename="requirements.txt"}
jupyter
matplotlib
numpy
```

::: {.callout-important}
`requirements.txt` is the only file that needs to be versioned by git.
:::

More details for using `venv` and `pip` can be found on the [quarto page dedicated to environments](https://quarto.org/docs/projects/virtual-environments.html#using-venv).

### What about `conda`?

For `conda` users, it is also possible to follow the same path with your favorite version of `conda`. There is a [quarto page dedicated to the conda environments](https://quarto.org/docs/projects/virtual-environments.html#using-conda).

## Continuous integration

The repository associated with this template is pre-configured to trigger an action on push that performs the following:

1. Check out the repository on an `ubuntu-latest` machine
2. Install quarto and dependencies, including the Computo extension
3. Install Python (3.10) and dependencies with `venv`, using your `requirements.txt` file
4. Render your .qmd file and Publish the results on a gh-page (both HTML and PDF)

The file [.github/workflows/build_n_publish.yml](https://github.com/computorg/template-computo-python/blob/main/.github/workflows/build_n_publish.yml) is largely inspired from [this file](https://quarto.org/docs/publishing/github-pages.html#example-jupyter-with-venv).

Once this is successful, you are ready to submit your manuscript to the [Computo submission platform](https://computo.scholasticahq.com/).

::: {.callout-warning}
The first time, you possibly need to create the branch for the action to work. This can be done by running the following command from your computer, in your git repository:

```.bash
quarto publish gh-pages
```

Then, set the branch `gh-page` as the source of your github page, and trigger the action to check that everything works fine.
:::

### What about CI and `conda`?

[The build and deploy process of our Computo quarto extension](https://github.com/computorg/computo-quarto-extension/blob/main/.github/workflows/build.yml) shows how `miniconda` can be set used in place of `venv`. The main striking difference is the use of a `environment.yml` file in place of `requirements.txt`.

## Data and large files

If your submission materials contain files larger than 50MB, **especially data files**, they won’t fit on a git repository as is. For this reason, we encourage you to put your data or any materials you deem necessary on an external “open data” centered repository hub such a [Zenodo](https://zenodo.org/) or [OSF](https://osf.io/).

# References {.unnumbered}

::: {#refs}
:::